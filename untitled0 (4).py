# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a3bq2i_sRBGY4mB-LWliOpAFqyZwxTo-
"""

import os
import json
import numpy as np
import torch
import torch.utils.data
from PIL import Image
import torchvision
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.transforms import functional as F
from tqdm import tqdm
from torchvision import transforms as T
from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import DataLoader
import torch.optim as optim

class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, root, annotation, transform=None):
        self.root = root
        self.transform = transform  # 변형을 클래스 외부에서 정의하고 인자로 전달받습니다.

        with open(annotation) as f:
            self.data = json.load(f)
        self.images = self.data['images']
        self.annotations = self.data['annotations']
        self.img_to_anns = {img['id']: [] for img in self.images}
        for ann in self.annotations:
            self.img_to_anns[ann['image_id']].append(ann)

    def __getitem__(self, idx):
        img_info = self.images[idx]
        img_path = os.path.join(self.root, img_info['file_name'])
        img = Image.open(img_path).convert("RGB")
        anns = self.img_to_anns[img_info['id']]
        boxes = [ann['bbox'] for ann in anns]
        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)
        boxes[:, 2:] += boxes[:, :2]
        labels = torch.as_tensor([ann['category_id'] for ann in anns], dtype=torch.int64)
        target = {"boxes": boxes, "labels": labels, "image_id": torch.tensor([img_info['id']])}

        if self.transform:
            img = self.transform(img)
        return img, target

    def __len__(self):
        return len(self.images)

class_id_to_name = {
    0: "background",  # 배경 클래스 추가
    1: ".",
    2: "0",
    3: "1",
    4: "2",
    5: "3",
    6: "4",
    7: "5",
    8: "6",
    9: "7",
    10: "8",
    11: "9",
    12: ".",
}

class RandomInvert(object):
    def __call__(self, img):
        if torch.rand(1) < 0.5:
            img = F.invert(img)
        return img

# 이미지를 50% 확률로 색상을 반전시키는 데 사용
transform = T.Compose([
    T.ToTensor(),  # PIL 이미지를 텐서로 변환
    RandomInvert(),  # 색반전 적용
    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)  # 명암 조절
])

import torch
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import DataLoader

class EarlyStopping:
    """얼리 스타핑을 위한 간단한 클래스입니다."""
    def __init__(self, patience=7, verbose=False, delta=0):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta

    def __call__(self, val_loss, model):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        '''모델이 개선될 때마다 모델을 저장합니다.'''
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), 'checkpoint.pt')
        self.val_loss_min = val_loss

def get_model(num_classes):
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    return model

"""* AP (Average Precision) @ IoU=0.50:0.95 (모든 영역 크기,  모든 IoU 임계값에 대한 평균)
* AP @ IoU=0.50 (모든 영역 크기, IoU=0.5)
* AP @ IoU=0.75 (모든 영역 크기, IoU=0.75)
8 AP for small, medium, and large objects (소, 중, 대 역 크기에 따른 AP)
* AR (Average Recall) for different number of detections (검출된 객체 수에 따른 평균 재현율)
"""

def train_one_epoch(model, optimizer, data_loader, device, epoch):
    model.train()
    loss_accum = 0.0
    for images, targets in tqdm(data_loader, desc=f"Epoch {epoch} Training"):
        images = list(img.to(device) for img in images)
        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
        loss_dict = model(images, targets)
        losses = sum(loss for loss in loss_dict.values())
        optimizer.zero_grad()
        losses.backward()
        optimizer.step()
        loss_accum += losses.item()
    return loss_accum / len(data_loader)



def evaluate(model, data_loader, device, annotation_file):
    model.eval()
    coco_gt = COCO(annotation_file)  # COCO 객체를 파일 경로를 사용하여 초기화
    coco_dt = []  # 모델 예측 결과를 저장할 리스트

    with torch.no_grad():
        for images, targets in tqdm(data_loader, desc="Evaluating"):
            images = list(img.to(device) for img in images)
            outputs = model(images)

            for i, output in enumerate(outputs):
                boxes = output['boxes'].cpu().numpy()
                labels = output['labels'].cpu().numpy()
                scores = output['scores'].cpu().numpy()

                image_id = targets[i]["image_id"].item()

                for j in range(len(boxes)):
                    # NumPy 데이터 타입을 Python의 네이티브 타입으로 변환
                    box = boxes[j].tolist()  # NumPy array를 리스트로 변환
                    label = int(labels[j])  # NumPy int64를 Python int로 변환
                    score = float(scores[j])  # 이미 float이지만 명시적으로 변환
                    coco_dt.append({
                        'image_id': image_id,
                        'category_id': label,
                        'bbox': [box[0], box[1], box[2] - box[0], box[3] - box[1]],  # x, y, width, height
                        'score': score
                    })

    # COCO 결과를 임시 JSON 파일로 저장
    temp_file_name = "temp_coco_dt.json"
    with open(temp_file_name, "w") as f:
        json.dump(coco_dt, f)

    coco_dt_loaded = coco_gt.loadRes(temp_file_name)

    coco_eval = COCOeval(coco_gt, coco_dt_loaded, "bbox")
    coco_eval.params.iouThrs = np.array([0.8])  # IoU 임계값을 0.5로 설정하여 단일 임계값에 대한 평가를 수행
    coco_eval.evaluate()
    coco_eval.accumulate()
    coco_eval.summarize()

    os.remove(temp_file_name)  # 임시 파일 삭제 후 추가 평가 지표 계산 및 출력

    # 추가 평가 지표 출력
    print("Precision, Recall, and F1-Score @ IoU=0.50")
    ap = coco_eval.stats[1]  # AP @ IoU=0.50 (index 1은 IoU=0.50에서의 AP를 의미)
    ar = coco_eval.stats[6]  # AR for maxDets=1 (index 6은 최대 검출 개수가 1개일 때의 평균 재현율(AR)을 의미)
    f1_score = 2 * (ap * ar) / (ap + ar) if (ap + ar) > 0 else 0  # AP와 AR을 사용하여 F1-Score 계산
    print(f"AP: {ap:.3f}, AR: {ar:.3f}, F1: {f1_score:.3f}")

    # mAP 값을 반환
    return coco_eval.stats[0]  # IoU=0.50:0.95, area=all, maxDets=100 경우의 평균 AP

# 데이터셋 경로와 파라미터 설정
train_dataset = CustomDataset(root='/content/drive/MyDrive/시현이/train', annotation='/content/drive/MyDrive/시현이/train/_annotations.coco.json',transform=transform)
valid_dataset = CustomDataset(root='/content/drive/MyDrive/시현이/valid', annotation='/content/drive/MyDrive/시현이/valid/_annotations.coco.json', transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))
valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))

def show_images(images, targets, class_id_to_name, num_images=2):
    fig, axs = plt.subplots(1, num_images, figsize=(20, 10))
    for i in range(num_images):
        img = images[i].permute(1, 2, 0)  # C x H x W to H x W x C
        img = img.numpy()
        target = targets[i]
        boxes = target['boxes'].cpu().numpy().astype(int)
        labels = target['labels'].cpu().numpy()

        axs[i].imshow(img)
        box_labels = []  # 박스의 x 좌표와 레이블을 저장할 리스트
        for box, label in zip(boxes, labels):
            rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], linewidth=1, edgecolor='r', facecolor='none')
            axs[i].add_patch(rect)
            class_name = class_id_to_name.get(label, 'Unknown')
            axs[i].text(box[0], box[1], class_name, color='blue', fontsize=30)
            box_labels.append((box[0], class_name))  # 박스의 x 좌표와 레이블 저장

        axs[i].axis('off')

        # 박스의 x 좌표를 기준으로 정렬
        box_labels.sort(key=lambda x: x[0])

        # 이미지 ID와 정렬된 레이블을 출력
        print(f"Image ID: {targets[i]['image_id'].item()}, Labels: {' '.join([label for _, label in box_labels])}")

    plt.show()

# DataLoader에서 데이터 배치를 가져옵니다.
images, targets = next(iter(train_loader))

# 시각화 함수를 호출합니다.
show_images(images, targets, class_id_to_name, num_images=min(2, len(images)))

# 모델과 옵티마이저 설정
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
num_classes = 12
model = get_model(num_classes)
model.to(device)

optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
num_epochs = 2

train_annotation_file = '/content/drive/MyDrive/시현이/train/_annotations.coco.json'
valid_annotation_file = '/content/drive/MyDrive/시현이/valid/_annotations.coco.json'

# 학습률 스케줄러 설정
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

early_stopping = EarlyStopping(patience=10, verbose=True)

for epoch in range(num_epochs):
    model.train()
    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)

    val_loss = evaluate(model, valid_loader, device, valid_annotation_file)
    print(f'Epoch {epoch}, Train loss: {train_loss}, Val loss: {val_loss}')

    lr_scheduler.step(val_loss)  # 스케줄러 업데이트

    # 얼리 스타핑 체크
    early_stopping(val_loss, model)
    if early_stopping.early_stop:
        print("Early stopping")
        break

# 모델 저장
if not os.path.exists('models'):
    os.makedirs('models')
torch.save(model.state_dict(), 'models/best_model.pth')

!pip install pycocotools

from pycocotools.coco import COCO
cocoGt = COCO(valid_annotation_file)

# num_epochs = 10
# best_loss = float('inf')

# # 모델 저장 경로 설정
# model_save_dir = './models'  # 모델을 저장할 디렉토리
# model_save_filename = 'best_model.pth'  # 모델 파일 이름
# model_save_path = os.path.join(model_save_dir, model_save_filename)  # 전체 모델 저장 경로

# # 모델 저장 디렉토리가 없으면 생성
# if not os.path.exists(model_save_dir):
#     os.makedirs(model_save_dir)

# for epoch in range(num_epochs):
#     train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)

#     # 유효성 검사 데이터셋 주석을 COCO 객체로 로드
#     valid_loss = evaluate(model, valid_loader, device, '/content/drive/MyDrive/시현이/valid/_annotations.coco.json')

#     print(f"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}")

#     # 최적 모델 저장
#     if valid_loss < best_loss:
#         best_loss = valid_loss
#         torch.save(model.state_dict(), model_save_path)  # 모델 저장 경로를 사용하여 모델 저장
#         print(f"Best model saved at {model_save_path} with Validation Loss: {best_loss:.4f}")

#     lr_scheduler.step()

# num_epochs = 1
# best_loss = float('inf')
# for epoch in range(num_epochs):
#     train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)

#     # 유효성 검사 데이터셋 주석을 COCO 객체로 로드
#     #cocoGt = COCO(valid_annotation_file)
#     valid_loss = evaluate(model, valid_loader, device, '/content/drive/MyDrive/시현이/valid/_annotations.coco.json')

#     print(f"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}")

#     # 최적 모델 저장
#     if valid_loss < best_loss:
#         best_loss = valid_loss
#         torch.save(model.state_dict(), 'best_model.pth')
#         print(f"Best model saved with Validation Loss: {best_loss:.4f}")

#     lr_scheduler.step()

# 테스트 데이터셋 로드
test_dataset = CustomDataset(root='/content/drive/MyDrive/시현이/test',
                             annotation='/content/drive/MyDrive/시현이/test/_annotations.coco.json',
                             transform=transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))


# 저장된 모델 로드
model.load_state_dict(torch.load('models/best_model.pth'))
model.to(device)
model.eval()

# 테스트 데이터셋에 대한 예측 및 평가
test_loss = evaluate(model, test_loader, device, '/content/drive/MyDrive/시현이/test/_annotations.coco.json')

print(f"Test Loss: {test_loss:.4f}")

# 저장된 모델 로드
model.load_state_dict(torch.load('best_model.pth'))
model.to(device)
model.eval()

def visualize_predictions(dataset, model, device):
    # 데이터셋의 모든 이미지에 대해 반복
    for i in range(len(dataset)):
        # 데이터셋에서 이미지와 타겟을 가져옵니다.
        img, _ = dataset[i]

        # 모델의 예측을 수행합니다.
        model.eval()
        with torch.no_grad():
            prediction = model([img.to(device)])

        # 예측 결과에서 바운딩 박스와 레이블, 점수를 추출합니다.
        boxes = prediction[0]['boxes']
        labels = prediction[0]['labels']
        scores = prediction[0]['scores']

        # PIL 이미지로 변환
        img = T.ToPILImage()(img.cpu())

        # 이미지와 예측된 바운딩 박스를 그립니다.
        plt.figure(figsize=(10,10))
        plt.imshow(img)
        ax = plt.gca()

        for box, label, score in zip(boxes, labels, scores):
            if score > 0.5:  # 점수가 0.5 이상인 바운딩 박스만 그립니다.
                x1, y1, x2, y2 = box.cpu().numpy()
                rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')
                ax.add_patch(rect)
                ax.text(x1, y1, f'{dataset.class_id_to_name[label.item()]}: {score:.2f}',
                        bbox=dict(facecolor='yellow', alpha=0.5), fontsize=10, color='black')
        plt.axis('off')
        plt.show()

# 이미지 시각화 실행
visualize_predictions(test_dataset, model, device)

